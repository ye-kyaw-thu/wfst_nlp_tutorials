{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0ba599e-db2b-4be3-84f6-602f2b48d5b9",
   "metadata": {},
   "source": [
    "# Demo of WFST-based POS Tagging\n",
    "## for Intern3 Students\n",
    "by Ye Kyaw Thu, Lab Leader, LST Lab., Myanmar  \n",
    "Date: 12 July 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f72b3-40a5-4bc2-9030-4483d5f2757f",
   "metadata": {},
   "source": [
    "## Shell Scripts\n",
    "\n",
    "ဒီ Lab မှာက OpenFST command တွေကို သုံးပြီး NLP field မှာ အရေးကြီးတဲ့ task တစ်ခုဖြစ်တဲ့ POS (Part-of-Speech) Tagging ကို လက်တွေ့ လုပ်ပြသွားမယ်။  \n",
    "ကိုယ့်စက်ထဲမှာ လိုက်လုပ်ဖို့အတွက်က လိုအပ်တဲ့ OpenFST နဲ့ တခြား python library တွေက ကြိုတင် installation လုပ်ထားရလိမ့်မယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a766d5-7e5a-40bf-9ba1-cdd921cc53a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/wfst_pos\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5255bb7-e340-4295-a396-1ea53a4f3044",
   "metadata": {},
   "source": [
    "Bash shell script တွေက အောက်ပါအတိုင်း"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7eca6cc-701e-4fb5-919f-817c6f3d0784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./shell_script/build_fst.sh\t   ./shell_script/rebuild.sh\n",
      "./shell_script/find_blank_line.sh  ./shell_script/run_tagger.sh\n",
      "./shell_script/pipe2space.sh\t   ./shell_script/run_wfst_pos.sh\n",
      "./shell_script/preprocess.sh\t   ./shell_script/test_tagger.sh\n"
     ]
    }
   ],
   "source": [
    "!ls ./shell_script/*.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b9dce0-1443-4441-a819-cbbb712a8a70",
   "metadata": {},
   "source": [
    "Python နဲ့ perl script တွေက အောက်ပါအတိုင်း"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5adbefcd-bafa-4002-80a2-ccf281fa9b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./script/build_lexicon.py  ./script/pos_evaluation.py\n",
      "./script/build_pos_lm.py   ./script/prepare_test_data.py\n",
      "./script/col2line.pl\t   ./script/preprocess.py\n",
      "./script/evaluate.py\n"
     ]
    }
   ],
   "source": [
    "!ls ./script/*.{py,pl}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664a58d-1e92-4b5e-afa3-63f392634560",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "\n",
    "POS Tagging အတွက် ဒေတာက LU Lab. ရဲ့ ဒေတာဖြစ်တဲ့ myPOS (Version 3.0) ကိုသုံးပါမယ်။  \n",
    "ဒေတာ download လုပ်တဲ့ အဆင့်ကို ကျော်ပါမယ်။  \n",
    "ဒေတာက publicly available ပါ။ အောက်ပါ လင့်ကနေ ယူသုံးနိုင်ပါတယ်။  \n",
    "[https://github.com/ye-kyaw-thu/myPOS/tree/master/corpus-ver-3.0](https://github.com/ye-kyaw-thu/myPOS/tree/master/corpus-ver-3.0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "418bb6e9-8a0f-4214-a3d5-ddeda29fbd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus.txt  mypos-ver.3.0.shuf.txt  otest.1k.txt  otest.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1008665-e236-4046-b240-c1c9dd30ff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  43196  537233 9581544 ./data/mypos-ver.3.0.shuf.txt\n",
      "   1000   12825  229758 ./data/otest.1k.txt\n",
      "  44196  550058 9811302 total\n"
     ]
    }
   ],
   "source": [
    "!wc ./data/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9f9fa8-8fbb-44b8-a305-699f46ff11a8",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "myPOS ဒေတာမှာက compound word တွေကို | (pipe) သင်္ကေတနဲ့တွဲထားတာမို့လို့ အဲဒီ pipe တွေကို ဖြုတ်ခဲ့တယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "251a985e-bb08-48f7-a4cd-1bcbc4dc4e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "လူ/n တိုင်း/part တွင်/ppm သင့်မြတ်/v လျော်ကန်/v စွာ/part ကန့်သတ်/v ထား/part သည့်/part အလုပ်/n လုပ်/v ချိန်/n အပြင်/conj ၊/punc လစာ/n နှင့်တကွ/conj အခါ/n ကာလ/n အားလျော်စွာ/ppm သတ်မှတ်/v ထား/part သည့်/part အလုပ်/n|အားလပ်ရက်/n များ/part ပါဝင်/v သည့်/part အနားယူခွင့်/n နှင့်/conj အားလပ်ခွင့်/n ခံစားပိုင်ခွင့်/n ရှိ/v သည်/ppm ။/punc\n",
      "စာပြန်ပွဲ/n ဆို/v တာ/part က/ppm အာဂုံဆောင်/v အလွတ်ကျက်/v ထား/part တဲ့/part ပိဋကတ်သုံးပုံ/n|စာပေ/n တွေ/part ကို/ppm စာစစ်/v|သံဃာတော်ကြီး/n တွေ/part ရဲ့/ppm ရှေ့/n မှာ/ppm အလွတ်/adv ပြန်/v ပြီး/part ရွတ်ပြ/v ရ/part တာ/part ပေါ့/part ။/punc\n",
      "၂ဝ/num ရာစု/n မြန်မာ့/n|သမိုင်း/n သန်းဝင်းလှိုင်/n ၊/punc ၂ဝဝ၉/num ခု/part ၊/punc မေ/n|လ/n ၊/punc ကံကော်ဝတ်ရည်/n|စာပေ/n ။/punc\n",
      "၅/num ရက်/n လောက်/part ပဲ/part အချိန်/n ရ/v တယ်/ppm ။/punc ရန်ကုန်/n မှာ/ppm ဘာ/pron လည်/v|စရာ/part တွေ/part ရှိ/v သလဲ/part ပြော/v ပါ/part ဦး/part ။/punc\n",
      "မြို့/n|လယ်/n တွင်/ppm ကား/part ကျိုက်သုတ်/n|စေတီ/n ရှိ/v သည်/ppm ။/punc\n",
      "ကျော်သူ/n ၁၉၅၉/num နိုဝင်ဘာ/n|လ/n ၂/num ရက်/n တွင်/ppm မွေးဖွား/v သည်/ppm ။/punc\n",
      "ဘာသာရေး/n|ပွဲတော်/n က/ppm ဘယ်/adj အချိန်/n မှာ/ppm စ/v မှာ/ppm လဲ/part ။/punc\n",
      "ဝန်ဆောင်/v|မှု/part ပိုင်း/part တွင်/ppm လည်း/part ကျွန်ုပ်/pron သင့်/pron အိမ်/n ဆောက်/v ရာတွင်/conj ကူညီ/v ခဲ့/part ပြီး/v ပြီ/part ဖြစ်/v ၍/conj ကျွန်ုပ်/pron အိမ်/n ကို/ppm လည်း/part ပြန်/part ကူ/v ဆောက်/v ပေး/part ပါ/part စသည်/part ဖြင့်/part ဖြစ်/v သည်/ppm ။/punc\n",
      "နာနတ်သီး/n|ဖျော်ရည်/n ၊/punc ဆီးသီး/n|ဖျော်ရည်/n ၊/punc သံပုရာရည်/n ၊/punc လိမ္မော်ရည်/n ၊/punc စပျစ်ရည်/n နည်းနည်း/adv ရှိ/v ပါ/part တယ်/ppm ။/punc\n",
      "ဤ/adj သဘော/n အတိုင်း/ppm ငှက်/n|သိုက်/n တို့/part ၏/ppm အဆင့်ဆင့်/adv တိုးတက်/v|ပြောင်းလဲ/v|လာ/part|ကြ/part|ပုံ/part ကို/ppm ယနေ့/n မြင်/v တွေ့/v ကြ/part ရ/part သော/part အသိုက်/n များ/part ကို/ppm လေ့လာ/v|ခြင်း/part ဖြင့်/ppm သိ/v အပ်/part သည်/ppm ။/punc\n",
      "grep: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!grep \"|\" ./data/mypos-ver.3.0.shuf.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2245d1-403e-4851-917c-846b04cc5b7a",
   "metadata": {},
   "source": [
    "**Linux/Unix မှာ powerful text processing command တစ်ခုဖြစ်တဲ့ sed (string editor) ကိုသုံးပြီး pipe တွေကို ဖြုတ်မယ်။**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e80ed1f-3665-4730-b81c-6e1f9073820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 's/|/ /g' ./data/mypos-ver.3.0.shuf.txt > ./data/corpus.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa47066-acaf-421e-bede-54e7991b181d",
   "metadata": {},
   "source": [
    "grep command နဲ့ pipe character ပါနေတဲ့ စာကြောင်းတွေ ရှိနေသေးသလား ဆိုတာကို confirm လုပ်မယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b8b607a-feb3-4ccd-af11-7018ccd9eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep \"|\" ./data/corpus.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "480dfc64-87e3-4d99-8e06-a8e404a5a083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  43196  564517 9581544 ./data/corpus.txt\n"
     ]
    }
   ],
   "source": [
    "!wc ./data/corpus.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e216a5-31ef-448d-bef8-9eb60d21cca4",
   "metadata": {},
   "source": [
    "open-test ဒေတာကိုဖိုင်ရဲ့ pipe တွေကိုလည်း ရှင်းခဲ့တယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4b13750-02b9-4acb-acda-61d475dbc869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "အေးချမ်း/v|မှု/part နဲ့/conj စည်းကမ်း/n ကို/ppm တည်မြဲ/v အောင်/part ထိန်းသိမ်း/v သည်/ppm ။/punc\n",
      "ကျွန်တော်/pron ငွေ/n|အရွက်/n|ကြီး/adj တွေ/part ရ/v မလား/part ။/punc\n",
      "ဒီ/adj နေ့/n ကမ္ဘာ့/n|စံချိန်သစ်/n တင်/v ခဲ့/part တယ်/ppm ။/punc\n",
      "အာဖရိက/n|တိုက်/n ၊/punc ဆီးရီးယား/n နှင့်/conj ပါးရှား/n|နိုင်ငံ/n ရှိ/v သဲကန္တာရ/n များ/part နှင့်/conj အိန္ဒိယ/n|နိုင်ငံ/n အလယ်/n|ပိုင်း/part ရှိ/v လွင်ပြင်/n များ/part တွင်/ppm မြင်းကျား/n နှင့်/conj မြည်း/n ရိုင်း/adj များ/part ကို/ppm တွေ့/v ရှိ/part နိုင်/part သည်/ppm ။/punc\n",
      "အင်္ဂါ/n|ဂြိုဟ်/n ပေါ်/n တွင်/ppm ယခု/n လက်ရှိ/adj အချိန်/n ၌/ppm ဝင်ရိုးစွန်း/n|ဒေသ/n များ/part မှ/part အပ/n ရေ/n မ/part ရှိ/v ပေ/part ။/punc\n",
      "ဗမာ/n|လူမျိုး/n တို့/part သည်/ppm တိဘက်/n မြန်မာ/n Tbeto/fw Burman/fw လူမျိုးနွယ်စု/n|ကြီး/part မှ/ppm အကြီးဆုံး/adj သော/part လူမျိုး/n ဖြစ်/v သည်/ppm ။/punc\n",
      "ရန်ကုန်/n|ဆေး/n|တက္ကသိုလ်/n ကို/ppm ဘယ်/adj မှတ်တိုင်/n မှာ/ppm ဆင်း/v ရ/part မှာ/ppm လဲ/part ။/punc\n",
      "အချို့/adj ငါး/n များ/part သည်/ppm မိမိ/pron တို့/part နေထိုင်/v|ရာ/part ပတ်ဝန်းကျင်/n အရောင်/n များ/part နှင့်/ppm လိုက်/v အောင်/conj မိမိ/pron တို့/part ၏/ppm အရောင်/n ကို/ppm ပြောင်းလဲ/v ပေး/part တတ်/part သည်/ppm ။/punc\n",
      "ပုံ/n မှာ/ppm အိန္ဒိယ/n|ဝန်ကြီးချုပ်/n မာမိုဟမ်ဆင်း/n နှင့်/conj အမေရိကန်/n|သမ္မတ/n ဂျော့ရှ်ဒဗလျူဘုရှ်/n တို့/part ၂၀၀၆/num ခုနှစ်/n မတ်/n|လ/n တွင်/ppm လက်ဆွဲနှုတ်ဆက်/v နေ/part ကြ/part ပုံ/n ဖြစ်/v သည်/ppm ။/punc\n",
      "မြင်း/n နှင့်/conj မြင်းကျား/n တို့/part တွင်/ppm အမြီး/n|ဖျား/n ၌/ppm သာ/part အမွေး/n ရှည်/adj များ/part ရှိ/v သည်/ppm ။/punc\n",
      "grep: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!grep \"|\" ./data/otest.1k.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50f04bd0-5647-4a6a-874f-61ca8c2debd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    257    5051  103365\n"
     ]
    }
   ],
   "source": [
    "!grep \"|\" ./data/otest.1k.txt | wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ba50ccf-5601-4b46-81fb-1551ad468c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 's/|/ /g' ./data/otest.1k.txt > ./data/otest.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9f308e8-1a0d-460b-a551-b266da85e354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1000  13468 229758 ./data/otest.txt\n"
     ]
    }
   ],
   "source": [
    "!wc ./data/otest.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e865a351-6e50-474a-af42-8eeaa9e1e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep \"|\" ./data/otest.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd777ca-5d17-4efe-8a88-3e126c1b73ec",
   "metadata": {},
   "source": [
    "## Hint\n",
    "လက်တွေ့ experiment တွေ လုပ်ကြတဲ့အခါမှာ ဒေတာပြောင်းလုပ်ရတာမျိုးလည်း ရှိလို့ ပြီးတော့ အသုံးဝင်တဲ့ command တွေက အလွတ်မှတ်မထားနိုင်ရင် bash shell script နဲ့ ရေးထားတာမျိုး လုပ်လို့ ရတယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6847d8a-a465-495a-aa6b-96b32441743e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "sed 's/|/ /g' ../data/mypos-ver.3.0.shuf.txt > ../data/corpus.txt\n",
      "sed 's/|/ /g' ../data/otest.1k.txt > ../data/otest.txt\n"
     ]
    }
   ],
   "source": [
    "!cat ./shell_script/pipe2space.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c119090-776e-495b-8269-b0137b6509de",
   "metadata": {},
   "source": [
    "ကိုယ်သုံးမယ့် ဒေတာပေါ်မူတည်ပြီး corpus ထဲမှာ blank line တွေပါတတ်တာမျိုးလည်း ရှိတာမို့ အဲဒါတွေကို ကြိုတင်ဖယ်ရှားထားတာက ကောင်းတယ်။ မဟုတ်ရင် experiment အတွက် သုံးခဲ့တဲ့ corpus စာကြောင်းအရေအတွက်ကို တင်ပြတဲ့အခါမှာ blank line တွေကိုပါ ထည့်ရေတွက်ထားတာမျိုးလည်း ဖြစ်သွားနိုင်လို့။ သုံးမယ့် code တွေအပေါ်မူတည်ပြီး လက်တွေ့ run ရတဲ့အခါမှာ blank line တွေကြောင့် error ဖြစ်တာမျိုးလည်း ရှိတယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68051144-1852-4c1d-b255-af7cc32acaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "# for printout filename and lineno of blank lines \n",
      "# written by Ye, NECTEC, Thailand\n",
      "# How to run: ./find-blank-lines.sh <filename or regular expression>\n",
      "# e.g. ./find-blank-lines.sh train.my\n",
      "# e.g. ./find-blank-lines.sh 't*.*' \n",
      "# Note: when you want to pass special characters such as *, you should use single quote!!!\n",
      "\n",
      "#find . -name \"$1\"  | xargs grep -E --line-number --with-filename '^$';\n",
      "find . -wholename \"$1\"  | xargs grep -E --line-number --with-filename '^$';\n"
     ]
    }
   ],
   "source": [
    "!cat ./shell_script/find_blank_line.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54769324-5fdb-452c-bf96-254eb10e74c5",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "**တကယ်တမ်း POS Tagging အတွက် သုံးမှာက corpus.txt နဲ့ otest.txt နှစ်ဖိုင်ပါ။**  \n",
    "အဲဒီဖိုင်နှစ်ဖိုင်ကနေပဲ WFST အတွက် လိုအပ်တဲ့ format အဖြစ်ပြောင်းဖို့အတွက် preprocessing လုပ်သွားတာမျိုးပါ။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ff67c93-6457-4bd5-86bf-58f1fa7030d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "mkdir ../fst\n",
      "# preprocess\n",
      "python ../script/preprocess.py ../data/corpus.txt ../fst/pairs.txt ../fst/words.syms ../fst/tags.syms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat ./shell_script/preprocess.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f08a00ba-5c07-459d-a1e9-24e73a227638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/wfst_pos\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2444795-fc82-40d2-b35c-746842d493b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/wfst_pos/shell_script\n"
     ]
    }
   ],
   "source": [
    "cd ./shell_script/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc71363b-6902-4839-a4cd-49b60fed4ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Output files: ../fst/pairs.txt, ../fst/words.syms, ../fst/tags.syms\n"
     ]
    }
   ],
   "source": [
    "!./preprocess.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2065649-54ef-4643-a451-2f78afc7dfef",
   "metadata": {},
   "source": [
    "ထွက်လာတဲ့ output ဖိုင်တွေကို စစ်ဆေးကြည့်မယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7bc4dd8-d591-4e15-911d-6e0a4797bc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  564517  1129034  9581272 ../fst/pairs.txt\n",
      "      22       44      197 ../fst/tags.syms\n",
      "   24827    49654   756965 ../fst/words.syms\n",
      "  589366  1178732 10338434 total\n"
     ]
    }
   ],
   "source": [
    "!wc ../fst/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ba873fd-4164-4977-8b77-c19f92c11d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "၁၉၆၂\tnum\n",
      "ခုနှစ်\tn\n",
      "ခန့်မှန်း\tv\n",
      "သန်းခေါင်စာရင်း\tn\n",
      "အရ\tppm\n",
      "လူဦးရေ\tn\n",
      "၁၁၅၉၃၁\tnum\n",
      "ယောက်\tpart\n",
      "ရှိ\tv\n",
      "သည်\tppm\n"
     ]
    }
   ],
   "source": [
    "!head ../fst/pairs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e450ff95-ada2-4c02-bf9a-a53f7fb5639d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<eps>\t0\n",
      "<unk>\t1\n",
      "abb\t2\n",
      "adj\t3\n",
      "adv\t4\n",
      "conj\t5\n",
      "fw\t6\n",
      "int\t7\n",
      "n\t8\n",
      "n/pron\t9\n"
     ]
    }
   ],
   "source": [
    "!head ../fst/tags.syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "226de4ae-4f4f-4bf5-a21f-cbfe7d85ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<eps>\t0\n",
      "!\t1\n",
      "\"\t2\n",
      "%\t3\n",
      "'\t4\n",
      "''\t5\n",
      "(\t6\n",
      ")\t7\n",
      "*\t8\n",
      "+\t9\n"
     ]
    }
   ],
   "source": [
    "!head ../fst/words.syms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c239c0-65ff-4fb9-a8eb-6d33e2617d2b",
   "metadata": {},
   "source": [
    "## Build FST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef9bf28e-e13b-42c5-8d38-3c834fdc9f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "# Default to bigram if not specified\n",
      "NGRAM=${1:-2}\n",
      "\n",
      "# Step 1: Build lexicon FST\n",
      "python ../script/build_lexicon.py ../fst/pairs.txt ../fst/lexicon.fst.txt ../fst/words.syms ../fst/tags.syms\n",
      "fstcompile --isymbols=../fst/words.syms --osymbols=../fst/tags.syms ../fst/lexicon.fst.txt ../fst/lexicon.fst\n",
      "\n",
      "# Step 2: Build POS LM FST with specified ngram\n",
      "python ../script/build_pos_lm.py ../fst/tags.syms ../fst/pairs.txt ../fst/pos_lm.fst.txt $NGRAM\n",
      "fstcompile --isymbols=../fst/tags.syms --osymbols=../fst/tags.syms ../fst/pos_lm.fst.txt ../fst/pos_lm.fst\n",
      "\n",
      "# Step 3: Compose lexicon and LM\n",
      "fstarcsort --sort_type=olabel ../fst/lexicon.fst > ../fst/lexicon_sorted.fst\n",
      "fstarcsort --sort_type=ilabel ../fst/pos_lm.fst > ../fst/pos_lm_sorted.fst\n",
      "fstcompose ../fst/lexicon_sorted.fst ../fst/pos_lm_sorted.fst ../fst/pos_tagger.fst\n",
      "\n",
      "echo \"FST model built: pos_tagger.fst (using ${NGRAM}-gram POS LM)\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat ./build_fst.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4edb1480-2421-4f54-a158-11018493345f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FST model built: pos_tagger.fst (using 2-gram POS LM)\n"
     ]
    }
   ],
   "source": [
    "!./build_fst.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442346b4-c847-4f8a-a65d-649ea3e10230",
   "metadata": {},
   "source": [
    "output အနေနဲ့ထွက်လာတဲ့ FST ဖိုင်တွေကို လေ့လာကြည့်ရအောင် ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd1e4438-80cb-49a9-baed-fd43aae5a60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lexicon.fst\t    pairs.txt\t    pos_lm_sorted.fst  words.syms\n",
      "lexicon.fst.txt     pos_lm.fst\t    pos_tagger.fst\n",
      "lexicon_sorted.fst  pos_lm.fst.txt  tags.syms\n"
     ]
    }
   ],
   "source": [
    "!ls ../fst/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "966621e9-0f00-4c16-b49a-58d62b5f55c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 ၁၉၆၂ num -1.0\n",
      "0 0 ခုနှစ် n -0.9937238493723849\n",
      "0 0 ခုနှစ် tn -0.006276150627615063\n",
      "0 0 ခန့်မှန်း v -0.9791666666666666\n",
      "0 0 ခန့်မှန်း n -0.020833333333333332\n",
      "0 0 သန်းခေါင်စာရင်း n -1.0\n",
      "0 0 အရ ppm -0.9932432432432432\n",
      "0 0 အရ part -0.0033783783783783786\n",
      "0 0 အရ conj -0.0033783783783783786\n",
      "0 0 လူဦးရေ n -1.0\n",
      "0 0 ၁၁၅၉၃၁ num -1.0\n",
      "0 0 ယောက် part -0.9868035190615836\n",
      "0 0 ယောက် n -0.007331378299120235\n",
      "0 0 ယောက် v -0.002932551319648094\n",
      "0 0 ယောက် tn -0.001466275659824047\n",
      "0 0 ယောက် ppm -0.001466275659824047\n",
      "0 0 ရှိ v -0.9368649008828919\n",
      "0 0 ရှိ part -0.06296851574212893\n",
      "0 0 ရှိ n -0.0001665833749791771\n",
      "0 0 သည် ppm -0.9972071256038647\n",
      "0 0 သည် part -0.002566425120772947\n",
      "0 0 သည် adj -7.548309178743961e-05\n",
      "0 0 သည် pron -7.548309178743961e-05\n",
      "0 0 သည် n -7.548309178743961e-05\n",
      "0 0 ။ punc -0.9998238816484678\n",
      "0 0 ။ part -8.805917576611483e-05\n",
      "0 0 ။ n -2.2014793941528707e-05\n",
      "0 0 ။ sb -4.4029587883057415e-05\n",
      "0 0 ။ ppm -2.2014793941528707e-05\n",
      "0 0 လူ n -0.9775510204081632\n"
     ]
    }
   ],
   "source": [
    "!head -n 30 ../fst/lexicon.fst.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "adde5bbb-28de-43c8-aa8f-6f614e6e169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 num num 0\n",
      "1 1 n n -0.6479299899023898\n",
      "1 1 part part -0.13917872770111073\n",
      "1 1 v v -0.035005048805116123\n",
      "1 1 adj adj -0.026758667115449344\n",
      "1 1 sb sb -0.017502524402558062\n",
      "1 1 ppm ppm -0.07303938067990576\n",
      "1 1 conj conj -0.011612251767081791\n",
      "1 1 tn tn -0.0013463480309660047\n",
      "1 1 num num -0.01666105688320431\n",
      "1 1 punc punc -0.024739145069000337\n",
      "1 1 fw fw -0.002019522046449007\n",
      "1 1 adv adv -0.002019522046449007\n",
      "1 1 pron pron -0.002019522046449007\n",
      "1 1 abb abb -0.0001682935038707506\n",
      "0 1 n n 0\n",
      "1 1 v v -0.14758727317112866\n",
      "1 1 ppm ppm -0.2667507527056717\n",
      "1 1 num num -0.021995280332004232\n",
      "1 1 part part -0.16896411424851493\n",
      "1 1 conj conj -0.02246724713158109\n",
      "1 1 n n -0.25762877370005693\n",
      "1 1 punc punc -0.03546260883717146\n",
      "1 1 tn tn -0.024184229799007244\n",
      "1 1 adv adv -0.015542354951582717\n",
      "1 1 adj adj -0.02674749776222638\n",
      "1 1 pron pron -0.007421271055415412\n",
      "1 1 fw fw -0.0045162340304337216\n",
      "1 1 abb abb -0.00048824151680364555\n",
      "1 1 sb sb -0.00018715924810806412\n"
     ]
    }
   ],
   "source": [
    "!head -n 30 ../fst/pos_lm.fst.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87173cbb-146f-48f9-b4b4-66dbcf23297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1\tA\tabb\t-0.100000001\n",
      "0\t1\tCAAC\tabb\t-1\n",
      "0\t1\tD\tabb\t-0.75\n",
      "0\t1\tG\tabb\t-0.125\n",
      "0\t1\tL\tabb\t-0.166666672\n",
      "0\t1\tN\tabb\t-0.5\n",
      "0\t1\tQQ\tabb\t-1\n",
      "0\t1\tU\tabb\t-0.166666672\n",
      "0\t1\tW\tabb\t-0.333333343\n",
      "0\t1\tYUFL\tabb\t-1\n",
      "0\t1\tဂျီ\tabb\t-0.125\n",
      "0\t1\tဂျီစီဘီအေ\tabb\t-1\n",
      "0\t1\tဂျီဒီ\tabb\t-1\n",
      "0\t1\tဂျီဒီပီ\tabb\t-1\n",
      "0\t1\tဂျီပီအိုင်\tabb\t-1\n",
      "0\t1\tဂျီအင်ပီ\tabb\t-1\n",
      "0\t1\tဂျီအိုအက်စ်\tabb\t-1\n",
      "0\t1\tဂျေစီဘီ\tabb\t-1\n",
      "0\t1\tဂျေအေအယ်လ်\tabb\t-1\n",
      "0\t1\tငြိမ်ပိ\tabb\t-1\n",
      "0\t1\tစကန\tabb\t-1\n",
      "0\t1\tစီ\tabb\t-0.00884955749\n",
      "0\t1\tစီစီတီဗွီ\tabb\t-1\n",
      "0\t1\tစီဒီ\tabb\t-1\n",
      "0\t1\tစီဒီအမ်အေ\tabb\t-1\n",
      "0\t1\tစီအင်အင်\tabb\t-1\n",
      "0\t1\tစီအိတ်စ်\tabb\t-1\n",
      "0\t1\tစီအီးအို\tabb\t-1\n",
      "0\t1\tတစည\tabb\t-1\n",
      "0\t1\tတီ\tabb\t-0.25\n"
     ]
    }
   ],
   "source": [
    "!fstprint --isymbols=../fst/words.syms --osymbols=../fst/tags.syms ../fst/pos_tagger.fst | head -n 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe388a-817c-4de8-9d64-e464138f856a",
   "metadata": {},
   "source": [
    "## Learn Well From Python Codes\n",
    "\n",
    "တကယ်တမ်း အခုလိုမျိုး FST ဖိုင် format အဖြစ်ပြောင်းထုတ်ဖို့က ကိုယ်တိုင် coding လုပ်ခဲ့ကြရတယ်။ ခုချိန်မှာက LLM တွေလည်း ရှိနေပြီမို့ အများကြီး လုပ်ရကိုင်ရ လွယ်ကူလာပါပြီ။  \n",
    "### build_lexicon.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41cae1b1-552e-4f18-b8cf-ca65b57757e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "for building FST lexicon\n",
      "Written by Ye Kyaw Thu, LU Lab., Myanmar.\n",
      "Last update: 10 July 2025\n",
      "Usage:  \n",
      "    python ./build_lexicon.py ../fst/pairs.txt ../fst/lexicon.fst.txt ../fst/words.syms ../fst/tags.syms\n",
      "\"\"\"\n",
      "\n",
      "import sys\n",
      "from collections import defaultdict\n",
      "\n",
      "def build_lexicon(pairs_file, lexicon_fst_file, words_syms, tags_syms):\n",
      "    \"\"\"Create a weighted lexicon FST (word -> POS) in OpenFST text format.\"\"\"\n",
      "    counts = defaultdict(lambda: defaultdict(int))\n",
      "    \n",
      "    # Read word-POS pairs and count (word, tag) frequencies\n",
      "    with open(pairs_file, 'r', encoding='utf-8') as f:\n",
      "        for line in f:\n",
      "            word, tag = line.strip().split('\\t')\n",
      "            counts[word][tag] += 1\n",
      "\n",
      "    # Write lexicon FST (weights = negative log probabilities)\n",
      "    with open(lexicon_fst_file, 'w', encoding='utf-8') as f:\n",
      "        for word, tags in counts.items():\n",
      "            total = sum(tags.values())\n",
      "            for tag, cnt in tags.items():\n",
      "                weight = -1 * (cnt / total)  # Tropical semiring\n",
      "                f.write(f'0 0 {word} {tag} {weight}\\n')\n",
      "        f.write('0 0\\n')  # Final state\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    if len(sys.argv) != 5:\n",
      "        print(\"Usage: python build_lexicon.py <pairs.txt> <lexicon.fst.txt> <words.syms> <tags.syms>\")\n",
      "        sys.exit(1)\n",
      "    \n",
      "    pairs_file = sys.argv[1]\n",
      "    lexicon_fst_file = sys.argv[2]\n",
      "    words_syms = sys.argv[3]\n",
      "    tags_syms = sys.argv[4]\n",
      "    \n",
      "    build_lexicon(pairs_file, lexicon_fst_file, words_syms, tags_syms)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat ../script/build_lexicon.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca66ddf-abf0-4d6c-82f5-882b786aa3e6",
   "metadata": {},
   "source": [
    "### build_pos_lm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d34051a-e76a-4003-ac8f-9d69b8d5e90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "for building FST LM\n",
      "Written by Ye Kyaw Thu, LU Lab., Myanmar.\n",
      "Last update: 10 July 2025\n",
      "Usage:\n",
      "    python ./build_pos_lm.py ../fst/tags.syms ../fst/pairs.txt ../fst/pos_lm.fst.txt 2\n",
      "\"\"\"\n",
      "\n",
      "import sys\n",
      "from collections import defaultdict\n",
      "\n",
      "def build_pos_lm(tags_syms, pairs_file, output_file, ngram=2):\n",
      "    \"\"\"Create POS ngram model (2-gram or 3-gram) from training data.\"\"\"\n",
      "    pos_counts = defaultdict(lambda: defaultdict(int))\n",
      "    total = defaultdict(int)\n",
      "    \n",
      "    # Read POS sequences from pairs.txt\n",
      "    with open(pairs_file, 'r', encoding='utf-8') as f:\n",
      "        history = []  # For ngram history\n",
      "        for line in f:\n",
      "            _, tag = line.strip().split('\\t')\n",
      "            \n",
      "            if ngram == 2:\n",
      "                # Bigram model\n",
      "                if len(history) == 1:\n",
      "                    prev_tag = history[0]\n",
      "                    pos_counts[prev_tag][tag] += 1\n",
      "                    total[prev_tag] += 1\n",
      "                history = [tag]\n",
      "                \n",
      "            elif ngram == 3:\n",
      "                # Trigram model\n",
      "                if len(history) == 2:\n",
      "                    context = tuple(history)\n",
      "                    pos_counts[context][tag] += 1\n",
      "                    total[context] += 1\n",
      "                history = history[-1:] + [tag] if len(history) > 0 else [tag]\n",
      "    \n",
      "    # Write POS ngram FST\n",
      "    with open(output_file, 'w', encoding='utf-8') as f:\n",
      "        if ngram == 2:\n",
      "            # Bigram transitions\n",
      "            for prev_tag, tags in pos_counts.items():\n",
      "                f.write(f\"0 1 {prev_tag} {prev_tag} 0\\n\")  # Initial transition\n",
      "                for tag, count in tags.items():\n",
      "                    prob = count / total[prev_tag]\n",
      "                    f.write(f\"1 1 {tag} {tag} {-1 * prob}\\n\")  # Transition\n",
      "            f.write(\"1 0\\n\")  # Final state\n",
      "            \n",
      "        elif ngram == 3:\n",
      "            # Trigram transitions\n",
      "            state_id = 1\n",
      "            context_map = {}  # Maps contexts to state IDs\n",
      "            \n",
      "            # Initial states for bigrams\n",
      "            for context in pos_counts:\n",
      "                context_map[context] = state_id\n",
      "                f.write(f\"0 {state_id} {context[0]} {context[0]} 0\\n\")\n",
      "                state_id += 1\n",
      "            \n",
      "            # Trigram transitions\n",
      "            for context, tags in pos_counts.items():\n",
      "                src_state = context_map[context]\n",
      "                for tag, count in tags.items():\n",
      "                    prob = count / total[context]\n",
      "                    new_context = (context[1], tag)\n",
      "                    \n",
      "                    if new_context not in context_map:\n",
      "                        context_map[new_context] = state_id\n",
      "                        state_id += 1\n",
      "                    \n",
      "                    f.write(f\"{src_state} {context_map[new_context]} {tag} {tag} {-1 * prob}\\n\")\n",
      "            \n",
      "            # Final states\n",
      "            for state in range(1, state_id):\n",
      "                f.write(f\"{state} 0\\n\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    if len(sys.argv) not in [4,5]:\n",
      "        print(\"Usage: python build_pos_lm.py <tags.syms> <pairs.txt> <pos_lm.fst.txt> [ngram=2]\")\n",
      "        print(\"  ngram: 2 for bigram (default), 3 for trigram\")\n",
      "        sys.exit(1)\n",
      "    \n",
      "    tags_syms = sys.argv[1]\n",
      "    pairs_file = sys.argv[2]\n",
      "    output_file = sys.argv[3]\n",
      "    ngram = int(sys.argv[4]) if len(sys.argv) > 4 else 2\n",
      "    \n",
      "    if ngram not in [2,3]:\n",
      "        print(\"Error: ngram must be 2 or 3\")\n",
      "        sys.exit(1)\n",
      "    \n",
      "    build_pos_lm(tags_syms, pairs_file, output_file, ngram)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat ../script/build_pos_lm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b2042-bf4b-427f-93a8-dfff7b10a80b",
   "metadata": {},
   "source": [
    "## POS Tagging  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88ff8712-abb6-43c1-be0b-80b1e81b225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "# Written by Ye Kyaw Thu, LU Lab., Myanmar\n",
      "# Last updated: 10 July 2025\n",
      "# How to run: time ./run_tagger.sh otest.txt words.syms tags.syms pos_tagger.fst > otest.hyp  \n",
      "\n",
      "rm ../fst/tagged_output.txt; \n",
      "\n",
      "TEST_FILE=\"$1\"\n",
      "WORDS_SYMS=\"$2\"\n",
      "TAGS_SYMS=\"$3\"\n",
      "POS_TAGGER_FST=\"$4\"\n",
      "\n",
      "# Create temporary directory\n",
      "TMPDIR=$(mktemp -d)\n",
      "trap 'rm -rf \"$TMPDIR\"' EXIT\n",
      "\n",
      "# Sort the POS tagger FST once\n",
      "fstarcsort --sort_type=ilabel \"$POS_TAGGER_FST\" > \"$TMPDIR/pos_tagger_sorted.fst\"\n",
      "\n",
      "# Process each sentence individually\n",
      "sentence_num=0\n",
      "while read -r sentence; do\n",
      "    if [ -z \"$sentence\" ]; then\n",
      "        continue  # Skip empty lines\n",
      "    fi\n",
      "    \n",
      "    # Store original sentence\n",
      "    echo \"$sentence\" > \"$TMPDIR/current_sentence.txt\"\n",
      "    \n",
      "    # Create FST for current sentence\n",
      "    python ../script/prepare_test_data.py \"$TMPDIR/current_sentence.txt\" \"$TMPDIR/sentence.fst.txt\" \"$WORDS_SYMS\"\n",
      "    \n",
      "    # Compile and sort sentence FST\n",
      "    fstcompile --isymbols=\"$WORDS_SYMS\" --osymbols=\"$WORDS_SYMS\" \\\n",
      "        \"$TMPDIR/sentence.fst.txt\" | \\\n",
      "        fstarcsort --sort_type=olabel > \"$TMPDIR/sentence.fst\"\n",
      "    \n",
      "    # Compose with POS tagger and get raw results\n",
      "    fstcompose \"$TMPDIR/sentence.fst\" \"$TMPDIR/pos_tagger_sorted.fst\" | \\\n",
      "        fstshortestpath | \\\n",
      "        fstprint --isymbols=\"$WORDS_SYMS\" --osymbols=\"$TAGS_SYMS\" > \"$TMPDIR/raw_output.txt\"\n",
      "    \n",
      "    # Use Python to reconstruct original order\n",
      "    python3 -c \"\n",
      "import sys\n",
      "from collections import OrderedDict\n",
      "\n",
      "# Read original sentence\n",
      "with open('$TMPDIR/current_sentence.txt', 'r', encoding='utf-8') as f:\n",
      "    original_words = [word.split('/')[0] for word in f.read().strip().split()]\n",
      "\n",
      "# Read FST output\n",
      "tag_map = OrderedDict()\n",
      "with open('$TMPDIR/raw_output.txt', 'r', encoding='utf-8') as f:\n",
      "    for line in f:\n",
      "        parts = line.strip().split()\n",
      "        if len(parts) >= 4 and parts[2] != '<eps>':\n",
      "            tag_map[parts[2]] = parts[3]\n",
      "\n",
      "# Output in original order\n",
      "for word in original_words:\n",
      "    print(f'{word}\\t{tag_map.get(word, \\\"<unk>\\\")}')\n",
      "print()  # Blank line between sentences\n",
      "\" >> ../fst/tagged_output.txt\n",
      "\n",
      "    sentence_num=$((sentence_num + 1))\n",
      "done < \"$TEST_FILE\"\n",
      "\n",
      "if [ $sentence_num -eq 0 ]; then\n",
      "    echo \"Error: No valid sentences found in input file\"\n",
      "    exit 1\n",
      "fi\n",
      "\n",
      "#echo \"Tagging completed. Processed $sentence_num sentences. Results:\"\n",
      "cat ../fst/tagged_output.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat ./run_tagger.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617095f-32e0-47c7-96ec-ffec20a77cc0",
   "metadata": {},
   "source": [
    "### Running run_tagger.sh\n",
    "\n",
    "run_tagger ကို run တဲ့အခါမှာ ကိုယ့်ရဲ့ test data ဖိုင်ပမာဏအပေါ်ကို မူတည်ပြီး စောင့်ရလိမ့်မယ်။  \n",
    "path တွေကို ဂရုစိုက် စစ်ပါ။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6dbf7348-b689-476f-aba5-24c129733c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t1m26.144s\n",
      "user\t1m17.298s\n",
      "sys\t0m19.746s\n"
     ]
    }
   ],
   "source": [
    "!time ./run_tagger.sh ../data/otest.txt ../fst/words.syms ../fst/tags.syms ../fst/pos_tagger.fst > ../fst/otest.hyp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c85ee3dd-6bf6-462d-a335-197e142e293a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lexicon.fst\t    otest.hyp\tpos_lm.fst.txt\t   tagged_output.txt\n",
      "lexicon.fst.txt     pairs.txt\tpos_lm_sorted.fst  tags.syms\n",
      "lexicon_sorted.fst  pos_lm.fst\tpos_tagger.fst\t   words.syms\n"
     ]
    }
   ],
   "source": [
    "!ls ../fst/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d7485-b041-4665-b9c5-ffb1a7b12486",
   "metadata": {},
   "source": [
    "ဆောက်လိုက်တဲ့ fst ဖိုင်ရဲ့ size ကိုလည်း စစ်ဆေးပါ။ ဥပမာ filesize က zero ဆိုရင်တော့ တနေရာရာမှာ လွဲနေပြီ။  \n",
    "OpenFST ကို သုံးရတဲ့အခါမှာ error ကို trace လိုက်တာက ခက်တယ်။ အလွယ်ဆုံးက ထွက်လာတဲ့ fst ဖိုင်တွေရဲ့ size က zero ဖြစ်နေလား ဆိုတာကို စစ်ကြည့်တာက တနည်းပါပဲ။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c2c5f1d-67b7-4ad8-a5c6-ebf69dc63240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1557     3942   441374 ../fst/lexicon.fst\n",
      "   27582   137907  1041303 ../fst/lexicon.fst.txt\n",
      "    1557     3072   441374 ../fst/lexicon_sorted.fst\n",
      "   14468    26936   229592 ../fst/otest.hyp\n",
      "  564517  1129034  9581272 ../fst/pairs.txt\n",
      "      32       57     3914 ../fst/pos_lm.fst\n",
      "     240     1197     7688 ../fst/pos_lm.fst.txt\n",
      "      32       55     3914 ../fst/pos_lm_sorted.fst\n",
      "   27639    72262  7686954 ../fst/pos_tagger.fst\n",
      "   14468    26936   229592 ../fst/tagged_output.txt\n",
      "      22       44      197 ../fst/tags.syms\n",
      "   24827    49654   756965 ../fst/words.syms\n",
      "  676941  1451096 20424139 total\n"
     ]
    }
   ],
   "source": [
    "!wc ../fst/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082beb96-e6ff-4c6a-9495-b0843b18c2cb",
   "metadata": {},
   "source": [
    "**နောက်ထပ် စစ်ဆေးလို့ ရတာက fstinfo commmand ကိုသုံးပြီး arc အရေအတွက်ကို ကြည့်တာမျိုးပါ။**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba5c89a6-0949-4328-a467-b99ffda1af11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fst type                                          vector\n",
      "arc type                                          standard\n",
      "input symbol table                                none\n",
      "output symbol table                               none\n",
      "# of states                                       1\n",
      "# of arcs                                         27581\n",
      "initial state                                     0\n",
      "# of final states                                 1\n",
      "# of input/output epsilons                        0\n",
      "# of input epsilons                               0\n",
      "# of output epsilons                              0\n",
      "input label multiplicity                          1.27606\n",
      "output label multiplicity                         9167.74\n",
      "# of accessible states                            1\n",
      "# of coaccessible states                          1\n",
      "# of connected states                             1\n",
      "# of connected components                         1\n",
      "# of strongly conn components                     1\n",
      "input matcher                                     n\n",
      "output matcher                                    n\n",
      "input lookahead                                   n\n",
      "output lookahead                                  n\n",
      "expanded                                          y\n",
      "mutable                                           y\n",
      "error                                             n\n",
      "acceptor                                          n\n",
      "input deterministic                               n\n",
      "output deterministic                              n\n",
      "input/output epsilons                             n\n",
      "input epsilons                                    n\n",
      "output epsilons                                   n\n",
      "input label sorted                                n\n",
      "output label sorted                               n\n",
      "weighted                                          y\n",
      "cyclic                                            y\n",
      "cyclic at initial state                           y\n",
      "top sorted                                        n\n",
      "accessible                                        y\n",
      "coaccessible                                      y\n",
      "string                                            n\n",
      "weighted cycles                                   y\n"
     ]
    }
   ],
   "source": [
    "!fstinfo ../fst/lexicon.fst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44d7a9-7304-4d33-bed9-d82d03300b75",
   "metadata": {},
   "source": [
    "**Language model ကိုလည်း fstinfo command နဲ့ လေ့လာကြည့်ရအောင်။**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93ff2cb1-342d-46cb-9528-9753137f0d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fst type                                          vector\n",
      "arc type                                          standard\n",
      "input symbol table                                none\n",
      "output symbol table                               none\n",
      "# of states                                       2\n",
      "# of arcs                                         239\n",
      "initial state                                     0\n",
      "# of final states                                 1\n",
      "# of input/output epsilons                        0\n",
      "# of input epsilons                               0\n",
      "# of output epsilons                              0\n",
      "input label multiplicity                          13.2343\n",
      "output label multiplicity                         13.2343\n",
      "# of accessible states                            2\n",
      "# of coaccessible states                          2\n",
      "# of connected states                             2\n",
      "# of connected components                         1\n",
      "# of strongly conn components                     2\n",
      "input matcher                                     n\n",
      "output matcher                                    n\n",
      "input lookahead                                   n\n",
      "output lookahead                                  n\n",
      "expanded                                          y\n",
      "mutable                                           y\n",
      "error                                             n\n",
      "acceptor                                          y\n",
      "input deterministic                               n\n",
      "output deterministic                              n\n",
      "input/output epsilons                             n\n",
      "input epsilons                                    n\n",
      "output epsilons                                   n\n",
      "input label sorted                                n\n",
      "output label sorted                               n\n",
      "weighted                                          y\n",
      "cyclic                                            y\n",
      "cyclic at initial state                           n\n",
      "top sorted                                        n\n",
      "accessible                                        y\n",
      "coaccessible                                      y\n",
      "string                                            n\n",
      "weighted cycles                                   y\n"
     ]
    }
   ],
   "source": [
    "!fstinfo ../fst/pos_lm.fst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d505be-0d80-4c5f-a740-d404ff6e7b27",
   "metadata": {},
   "source": [
    "**POS Tagger FST model ဖိုင်ကိုလည်း fstinfo command နဲ့ လေ့လာကြည့်ရအောင်။**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c6a29baa-357d-440e-b3d5-558f97d867f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fst type                                          vector\n",
      "arc type                                          standard\n",
      "input symbol table                                none\n",
      "output symbol table                               none\n",
      "# of states                                       2\n",
      "# of arcs                                         480429\n",
      "initial state                                     0\n",
      "# of final states                                 1\n",
      "# of input/output epsilons                        0\n",
      "# of input epsilons                               0\n",
      "# of output epsilons                              0\n",
      "input label multiplicity                          19.7019\n",
      "output label multiplicity                         151254\n",
      "# of accessible states                            2\n",
      "# of coaccessible states                          2\n",
      "# of connected states                             2\n",
      "# of connected components                         1\n",
      "# of strongly conn components                     2\n",
      "input matcher                                     n\n",
      "output matcher                                    y\n",
      "input lookahead                                   n\n",
      "output lookahead                                  n\n",
      "expanded                                          y\n",
      "mutable                                           y\n",
      "error                                             n\n",
      "acceptor                                          n\n",
      "input deterministic                               n\n",
      "output deterministic                              n\n",
      "input/output epsilons                             n\n",
      "input epsilons                                    n\n",
      "output epsilons                                   n\n",
      "input label sorted                                n\n",
      "output label sorted                               y\n",
      "weighted                                          y\n",
      "cyclic                                            y\n",
      "cyclic at initial state                           n\n",
      "top sorted                                        n\n",
      "accessible                                        y\n",
      "coaccessible                                      y\n",
      "string                                            n\n",
      "weighted cycles                                   y\n"
     ]
    }
   ],
   "source": [
    "!fstinfo ../fst/pos_tagger.fst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1794c-5b3a-4fd4-bb87-a30938d4ce83",
   "metadata": {},
   "source": [
    "**ကိုယ့်ရဲ့ WFST POS Tagger က တကယ်တမ်း အလုပ် လုပ်တယ် မလုပ်ဘူး ဆိုတာကို အမြန်ဆုံး သိချင်ရင်တော့ မော်ဒယ်က tag လုပ်ပေးထားတဲ့ဖိုင်ရဲ့ အတွင်းပိုင်းကို ဝင်ကြည့်တာပါပဲ။**\n",
    "## Check otest.hyp File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3912d3a0-ac54-4f12-a821-ee65f4c38552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "တစ်\ttn\n",
      "ကိုက်\tv\n",
      "ကို\tppm\n",
      "ဝမ်\tn\n",
      "ခုနှစ်ထောင်\ttn\n",
      "ပါ\tpart\n",
      "။\tpunc\n",
      "\n",
      "မနှစ်\tn\n",
      "က\tppm\n",
      "သူ\tn\n",
      "ကျွန်မ\tpron\n",
      "ကို\tppm\n",
      "သင်\tv\n",
      "ပေး\tv\n",
      "တယ်\tppm\n",
      "။\tpunc\n",
      "\n",
      "ကျွန်တော့်\tpron\n",
      "ခုံ\tn\n",
      "သွား\tv\n",
      "ရှာ\tv\n",
      "မလို့\tpart\n",
      "။\tpunc\n",
      "\n",
      "အတန်း\tn\n",
      "စ\tv\n",
      "တာ\tpart\n",
      "ကြာ\tv\n",
      "ပြီ\tppm\n"
     ]
    }
   ],
   "source": [
    "!head -n 30 ../fst/otest.hyp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c133966-9f97-47db-bf3f-0c5626f046c8",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "WFST model က ဘယ်လောက်ထိ မှန်မှန်ကန်ကန် tagging လုပ်ပေးနိုင်သလဲ ဆိုတာကိုတော့ လူကိုယ်တိုင် tagging လုပ်ထားတဲ့ reference ဖိုင်နဲ့ တိုင်းတာကြည့်ရပါတယ်။  \n",
    "အဲဒီလို တိုင်းတာနိုင်ဖို့အတွက် အရင်ဆုံး အထက်မှာ မြင်ရတဲ့အတိုင်း two column format ဖိုင်ကို ပုံမှန် line by line format ဖြစ်အောင် ပြောင်းလဲဖို့ လိုအပ်ပါတယ်။   \n",
    "အဲဒီအတွက်ကိုတော့ col2line.pl (perl program) ကို သုံးပါမယ်။  \n",
    "NLP preprocessing, post-editing အလုပ်အတွက် သုံးခဲ့တဲ့ script တချို့ကို GitHub မှာတင်ပေးထားပါတယ်။  \n",
    "GitHub Link for Tools: [https://github.com/ye-kyaw-thu/tools](https://github.com/ye-kyaw-thu/tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd52f043-17a7-46a8-b038-1f768ed2bc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/perl\n",
      "use strict;\n",
      "use utf8;\n",
      "\n",
      "# last updated 16 May 2017\n",
      "# written by Ye Kyaw Thu\n",
      "# change column to line format\n",
      "\n",
      "binmode(STDIN, \":utf8\");\n",
      "binmode(STDOUT, \":utf8\");\n",
      "binmode(STDERR, \":utf8\");\n",
      "\n",
      "open (col_FILE, \"<:encoding(utf8)\", $ARGV[0]) or die \"Couldn\\'t open input file $ARGV[0]!, $!\\n\";\n",
      "\n",
      "my $tmpLine;\n",
      "foreach my $line (<col_FILE>)\n",
      "{\n",
      "   chomp($line);\n",
      "\n",
      "   if($line ne \"\")\n",
      "   {\n",
      "      $line =~ s/\\t/\\//;\n",
      "      $tmpLine = $tmpLine.$line.\" \";\n",
      "   }else\n",
      "   {\n",
      "      $tmpLine =~ s/\\s+$//;\n",
      "      print $tmpLine.\"\\n\";\n",
      "      $tmpLine = \"\";\n",
      "   }\n",
      "}\n",
      "close (col_FILE);\n"
     ]
    }
   ],
   "source": [
    "!cat ../script/col2line.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f36e3-205d-4563-9e83-cade5b8573a8",
   "metadata": {},
   "source": [
    "### Column to Line Format Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52451ecc-b5e7-47b5-9387-98b0ef25e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl ../script/col2line.pl ../fst/otest.hyp > ../fst/otest.hyp.line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdbf85d-e7ff-4afb-baf4-e6d3ee9a45a4",
   "metadata": {},
   "source": [
    "Perl program နဲ့ format ပြောင်းပြီး ထွက်လာတဲ့ ဖိုင်ကိုလည်း စစ်ဆေးကြည့်ရအောင်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "32ab6277-cc21-45d3-bbaf-0fd40eb4c92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "တစ်/tn ကိုက်/v ကို/ppm ဝမ်/n ခုနှစ်ထောင်/tn ပါ/part ။/punc\n",
      "မနှစ်/n က/ppm သူ/n ကျွန်မ/pron ကို/ppm သင်/v ပေး/v တယ်/ppm ။/punc\n",
      "ကျွန်တော့်/pron ခုံ/n သွား/v ရှာ/v မလို့/part ။/punc\n",
      "အတန်း/n စ/v တာ/part ကြာ/v ပြီ/ppm လား/part ။/punc\n",
      "ဆေး/n နည်းနည်း/adj စား/v လိုက်/part ၊/punc သုံး/v လေး/part ရက်/n လောက်/part အနားယူ/v လိုက်/part ရင်/conj ပျောက်/v သွား/v မှာ/ppm ပါ/part ။/punc\n",
      "အေးချမ်း/v မှု/part နဲ့/ppm စည်းကမ်း/n ကို/ppm တည်မြဲ/v အောင်/v ထိန်းသိမ်း/v သည်/ppm ။/punc\n",
      "ဇွန်း/n ကို/ppm လိုအပ်/v တယ်/ppm ။/punc\n",
      "ဘွဲ့/n ရ/v ရင်/conj ဘာ/adj လုပ်/v မ/part လို့/part လဲ/part ။/punc\n",
      "ကျွန်တော်/pron ချောင်းဆိုး/v ခြင်း/part အတွက်/ppm တစ်/tn ခု/part ခု/part လို/v ချင်/part တယ်/ppm ။/punc\n",
      "အသီးအနှံ/n တို့/part မှ/ppm လွဲ/v လျှင်/adj လူ/n တို့/part ၏/ppm အဓိက/n အစားအစာ/n မှာ/ppm ငါး/n ဖြစ်/v သည်/ppm ။/punc\n"
     ]
    }
   ],
   "source": [
    "!head ../fst/otest.hyp.line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61469800-3fb0-4039-9fe6-b2334d3b4ac3",
   "metadata": {},
   "source": [
    "**Reference ဖိုင်ကို သုံးပြီး Evaluation လုပ်ကြည့်မယ်။**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da0e5d03-d5dd-41ee-9a75-01eb536206d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.66% (12345/13468)\n",
      "\n",
      "Most common mistakes:\n",
      "ရ/part --> ရ/v\t91\n",
      "ပြီး/conj --> ပြီး/v\t73\n",
      "ပေး/part --> ပေး/v\t47\n",
      "သွား/part --> သွား/v\t36\n",
      "ဒီ/pron --> ဒီ/adj\t32\n",
      "နှင့်/ppm --> နှင့်/conj\t21\n",
      "နဲ့/conj --> နဲ့/ppm\t19\n",
      "ဘာ/pron --> ဘာ/adj\t18\n",
      "နှစ်/tn --> နှစ်/n\t18\n",
      "လာ/v --> လာ/part\t18\n"
     ]
    }
   ],
   "source": [
    "!python ../script/pos_evaluation.py --ref ../data/otest.txt --hyp ../fst/otest.hyp.line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854902dd-cf95-4d12-adf3-2ebb7ee2e69e",
   "metadata": {},
   "source": [
    "**--top-k ဆိုတဲ့ commandline option နဲ့ အမှားအများဆုံး အတွဲ ၃၀ ကို print ရိုက်ထုတ်ခိုင်းကြည့်ရအောင်။**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81f68daa-d88a-418a-992d-460f88ade1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.66% (12345/13468)\n",
      "\n",
      "Most common mistakes:\n",
      "ရ/part --> ရ/v\t91\n",
      "ပြီး/conj --> ပြီး/v\t73\n",
      "ပေး/part --> ပေး/v\t47\n",
      "သွား/part --> သွား/v\t36\n",
      "ဒီ/pron --> ဒီ/adj\t32\n",
      "နှင့်/ppm --> နှင့်/conj\t21\n",
      "နဲ့/conj --> နဲ့/ppm\t19\n",
      "ဘာ/pron --> ဘာ/adj\t18\n",
      "နှစ်/tn --> နှစ်/n\t18\n",
      "လာ/v --> လာ/part\t18\n",
      "ဘယ်လောက်/adv --> ဘယ်လောက်/adj\t16\n",
      "ဘယ်/pron --> ဘယ်/adj\t16\n",
      "ဟာ/ppm --> ဟာ/n\t16\n",
      "ပြီး/part --> ပြီး/v\t16\n",
      "များ/adj --> များ/part\t15\n",
      "နဲ့/part --> နဲ့/ppm\t14\n",
      "သူ/pron --> သူ/n\t13\n",
      "ဟာ/part --> ဟာ/n\t12\n",
      "လျှင်/conj --> လျှင်/adj\t11\n",
      "နေ/v --> နေ/part\t11\n",
      "မှာ/v --> မှာ/ppm\t11\n",
      "ရန်/conj --> ရန်/n\t11\n",
      "ဘယ်လို/adv --> ဘယ်လို/adj\t10\n",
      "လေး/tn --> လေး/part\t9\n",
      "ရှိ/part --> ရှိ/v\t9\n",
      "သိပ်/adv --> သိပ်/v\t9\n",
      "ကြီး/adj --> ကြီး/part\t8\n",
      "ပါ/v --> ပါ/part\t8\n",
      "တောင်/part --> တောင်/n\t8\n",
      "၎င်း/pron --> ၎င်း/adj\t8\n"
     ]
    }
   ],
   "source": [
    "!python ../script/pos_evaluation.py --ref ../data/otest.txt --hyp ../fst/otest.hyp.line --top-k 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecc2882-97ae-46ac-bfef-020e7fc6b545",
   "metadata": {},
   "source": [
    "## pos_evaluation.py\n",
    "ဒီ python code က POS tagging အပြင်တခြား tagging evaluation တွေအတွက်လည်း အသုံးဝင်ပါလိမ့်မယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ebc2b19-384f-488a-a94f-5a6d1ec83a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "Evaluation for POS Tagging, NER Tagging etc.\n",
      "Written by Ye Kyaw Thu, LU Lab., Myanmar.\n",
      "Last Update: 10 July 2025\n",
      "Usage:\n",
      "    python ./pos_evaluation.py --ref ../data/otest.txt --hyp ../fst/otest.hyp.line --top-k 30\n",
      "\"\"\"\n",
      "\n",
      "import sys\n",
      "import argparse\n",
      "from collections import defaultdict\n",
      "\n",
      "def main():\n",
      "    parser = argparse.ArgumentParser(description='Compare reference and hypothesis files for accuracy.')\n",
      "    parser.add_argument('--ref', type=str, help='Reference file (default: stdin)')\n",
      "    parser.add_argument('--hyp', type=str, help='Hypothesis file (default: stdin)')\n",
      "    parser.add_argument('--top-k', type=int, default=10, \n",
      "                      help='Number of top mistakes to display (default: 10)')\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    # Handle input files or stdin\n",
      "    ref_file = sys.stdin if args.ref is None else open(args.ref, 'r', encoding='utf-8')\n",
      "    hyp_file = sys.stdin if args.hyp is None else open(args.hyp, 'r', encoding='utf-8')\n",
      "\n",
      "    mistakes = defaultdict(int)\n",
      "    total = 0\n",
      "    correct = 0\n",
      "\n",
      "    for s0, s1 in zip(ref_file, hyp_file):\n",
      "        s0 = s0.strip()\n",
      "        s1 = s1.strip()\n",
      "        a0 = s0.split()\n",
      "        a1 = s1.split()\n",
      "\n",
      "        if len(a0) != len(a1):\n",
      "            print(f\"Line lengths don't match:\\n{' '.join(a0)}\\n{' '.join(a1)}\", file=sys.stderr)\n",
      "            sys.exit(1)\n",
      "\n",
      "        for w0, w1 in zip(a0, a1):\n",
      "            # Remove everything after and including underscore\n",
      "            w0_clean = w0.split('_')[0]\n",
      "            w1_clean = w1.split('_')[0]\n",
      "            \n",
      "            total += 1\n",
      "            if w0_clean == w1_clean:\n",
      "                correct += 1\n",
      "            else:\n",
      "                mistake = f\"{w0_clean} --> {w1_clean}\"\n",
      "                mistakes[mistake] += 1\n",
      "\n",
      "    # Close files if they were opened (not stdin)\n",
      "    if args.ref is not None:\n",
      "        ref_file.close()\n",
      "    if args.hyp is not None:\n",
      "        hyp_file.close()\n",
      "\n",
      "    # Calculate and print accuracy\n",
      "    accuracy = (correct / total) * 100 if total > 0 else 0\n",
      "    print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total})\\n\\nMost common mistakes:\")\n",
      "\n",
      "    # Print top mistakes\n",
      "    for i, (mistake, count) in enumerate(sorted(mistakes.items(), key=lambda x: x[1], reverse=True)):\n",
      "        if i >= args.top_k:\n",
      "            break\n",
      "        print(f\"{mistake}\\t{count}\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat ../script/pos_evaluation.py "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213742a7-b362-4add-a818-4e07080a4f41",
   "metadata": {},
   "source": [
    "## --help of pos_evaluation.py Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ebbddb60-c964-4e66-87f6-72a0f8a75c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: pos_evaluation.py [-h] [--ref REF] [--hyp HYP] [--top-k TOP_K]\n",
      "\n",
      "Compare reference and hypothesis files for accuracy.\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --ref REF      Reference file (default: stdin)\n",
      "  --hyp HYP      Hypothesis file (default: stdin)\n",
      "  --top-k TOP_K  Number of top mistakes to display (default: 10)\n"
     ]
    }
   ],
   "source": [
    "!python ../script/pos_evaluation.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b610dd-7211-4e95-8c81-01db302df3b5",
   "metadata": {},
   "source": [
    "## Building 3gram FST Model\n",
    "\n",
    "အထက်က ရခဲ့တဲ့ ရလဒ်က 2gram Language Model နဲ့ပါ။  \n",
    "ဒီတခါတော့ 3gram POS LM ဆောက်ကြည့်ပြီးတော့ ရလဒ်ဘယ်လောက်ထိ တက်လာသလဲ ဆိုတာကို လေ့လာကြည့်ရအောင်။  \n",
    "အထက်ပါအတိုင်း command တွေ တစ်ခုချင်း ပေးပြီး run ရင်လည်း ရပေမယ့် ဒီတခါတော့ ရေးထားတဲ့ shell script ကိုသုံးပြီး အမြန် run သွားပါမယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1ec28567-b072-47fe-87cf-263b1db8ac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_fst.sh\t    pipe2space.sh  rebuild.sh\t  run_wfst_pos.sh\n",
      "find_blank_line.sh  preprocess.sh  run_tagger.sh  test_tagger.sh\n"
     ]
    }
   ],
   "source": [
    "!ls *.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "290439e0-adf1-4cb8-add7-39ab97895605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "# Default to bigram, but allow override\n",
      "NGRAM=${1:-2}\n",
      "\n",
      "# Clean previous files\n",
      "rm -f ../fst/*.fst ../fst/*.fst.txt\n",
      "\n",
      "# Rebuild from scratch\n",
      "./preprocess.sh\n",
      "./build_fst.sh $NGRAM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat ./rebuild.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd623caf-3123-4c35-9f25-50ca2a6589c4",
   "metadata": {},
   "source": [
    "**commandline argument အနေနဲ့ \"3\" ကို ရိုက်ထည့်ဖို့ မမေ့နဲ့ဦး။**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba80552f-7b81-4b52-ba96-cb6a7b4eb0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../fst’: File exists\n",
      "Preprocessing complete. Output files: ../fst/pairs.txt, ../fst/words.syms, ../fst/tags.syms\n",
      "FST model built: pos_tagger.fst (using 3-gram POS LM)\n",
      "\n",
      "real\t0m1.195s\n",
      "user\t0m1.069s\n",
      "sys\t0m0.119s\n"
     ]
    }
   ],
   "source": [
    "!time ./rebuild.sh 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "78cb2ef9-2bfc-42f0-9203-147f10b18399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  564517  1129034  9581272 ../fst/pairs.txt\n",
      "   24827    49654   756965 ../fst/words.syms\n",
      "      22       44      197 ../fst/tags.syms\n",
      "  589366  1178732 10338434 total\n"
     ]
    }
   ],
   "source": [
    "!wc ../fst/pairs.txt ../fst/words.syms ../fst/tags.syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3ee64814-23b9-4131-ade3-174847ed220c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1557     3942   441374 ../fst/lexicon.fst\n",
      "    1557     3072   441374 ../fst/lexicon_sorted.fst\n",
      "     287      523    34066 ../fst/pos_lm.fst\n",
      "     287      538    34066 ../fst/pos_lm_sorted.fst\n",
      "  236038  1089633 81434994 ../fst/pos_tagger.fst\n",
      "  239726  1097708 82385874 total\n"
     ]
    }
   ],
   "source": [
    "!wc ../fst/*.fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1c2183c-9a89-4380-a5f0-dae7c041e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../fst/lexicon.fst.txt\t../fst/pos_lm.fst.txt\n",
      "../fst/pairs.txt\t../fst/tagged_output.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ../fst/*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ce6c5183-e2c8-4b7a-a88d-4726a1e27df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 num num 0\n",
      "0 2 n n 0\n",
      "0 3 v v 0\n",
      "0 4 n n 0\n",
      "0 5 ppm ppm 0\n",
      "0 6 n n 0\n",
      "0 7 num num 0\n",
      "0 8 part part 0\n",
      "0 9 v v 0\n",
      "0 10 ppm ppm 0\n",
      "0 11 punc punc 0\n",
      "0 12 n n 0\n",
      "0 13 part part 0\n",
      "0 14 ppm ppm 0\n",
      "0 15 v v 0\n",
      "0 16 v v 0\n",
      "0 17 part part 0\n",
      "0 18 part part 0\n",
      "0 19 n n 0\n",
      "0 20 conj conj 0\n",
      "0 21 conj conj 0\n",
      "0 22 n n 0\n",
      "0 23 punc punc 0\n",
      "0 24 adj adj 0\n",
      "0 25 ppm ppm 0\n",
      "0 26 adv adv 0\n",
      "0 27 part part 0\n",
      "0 28 punc punc 0\n",
      "0 29 pron pron 0\n",
      "0 30 ppm ppm 0\n"
     ]
    }
   ],
   "source": [
    "!head -n 30 ../fst/pos_lm.fst.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75af28-b4b5-467b-8424-3880d044be22",
   "metadata": {},
   "source": [
    "## POS Tagging with 3-gram LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "645cfa38-f7e9-465b-9be9-1fed6463b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ye/exp/wfst_pos/shell_script\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5d6235fe-b547-4f29-b70d-39f637c2885f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t4m7.175s\n",
      "user\t3m34.467s\n",
      "sys\t0m45.863s\n"
     ]
    }
   ],
   "source": [
    "!time ./run_tagger.sh ../data/otest.txt ../fst/words.syms ../fst/tags.syms ../fst/pos_tagger.fst > ../fst/otest_3gram.hyp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfa50db-d13a-4957-b32c-e0a7954416e3",
   "metadata": {},
   "source": [
    "Tagging လုပ်တဲ့ process နှစ်ခုကို နှိုင်းယှဉ်ကြည့်ရင် 3-gram LM က 2-gram LM ထက် ပိုကြာတာကို တွေ့ရပါလိမ့်မယ်။ ၄မိနစ်နဲ့ ၇စက္ကန့်ကြာပါတယ်။  \n",
    "ကောင်းပြီ။ 2-gram မော်ဒယ်ထက် tagging performance က ဘယ်လောက်ထိ တက်လာသလဲ ဆိုတာကို evaluation လုပ်ကြည့်ရအောင်။  \n",
    "\n",
    "## Evaluation with 3-gram LM\n",
    "\n",
    "အရင်ဆုံး blank file ဖြစ်မဖြစ် wc command နဲ့ စစ်ကြည့်ရအောင်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b914a8d4-fd81-433c-9950-c2a90cf26749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14468  26936 230687 ../fst/otest_3gram.hyp\n"
     ]
    }
   ],
   "source": [
    "!wc ../fst/otest_3gram.hyp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb4d0c-38d0-4730-b967-b1cd856982a2",
   "metadata": {},
   "source": [
    "File အတွင်းပိုင်းကိုလည်း မျက်စိနဲ့ တချက်ကြည့်ကြည့်ရအောင်...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "07971253-7b0e-4374-bb6b-a39f08e8c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "တစ်\ttn\n",
      "ကိုက်\tv\n",
      "ကို\tppm\n",
      "ဝမ်\tn\n",
      "ခုနှစ်ထောင်\ttn\n",
      "ပါ\tpart\n",
      "။\tpunc\n",
      "\n",
      "မနှစ်\tn\n",
      "က\tppm\n",
      "သူ\tn\n",
      "ကျွန်မ\tpron\n",
      "ကို\tppm\n",
      "သင်\tv\n",
      "ပေး\tpart\n",
      "တယ်\tppm\n",
      "။\tpunc\n",
      "\n",
      "ကျွန်တော့်\tpron\n",
      "ခုံ\tn\n",
      "သွား\tpart\n",
      "ရှာ\tv\n",
      "မလို့\tpart\n",
      "။\tpunc\n",
      "\n",
      "အတန်း\tn\n",
      "စ\tv\n",
      "တာ\tpart\n",
      "ကြာ\tv\n",
      "ပြီ\tppm\n"
     ]
    }
   ],
   "source": [
    "!head -n 30 ../fst/otest_3gram.hyp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c4b408-90c1-4851-b463-feabd51bd6c5",
   "metadata": {},
   "source": [
    "**အခြေအနေကောင်းပုံ ရတယ်။  :)**  \n",
    "\n",
    "column format ကနေ line format အဖြစ်ပြောင်းရဦးမယ်။  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e78b11a0-68b3-4ec4-95f7-e0499fafd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl ../script/col2line.pl ../fst/otest_3gram.hyp > ../fst/otest_3gram.hyp.line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "005701ef-d5aa-4a9a-99aa-8b94129639a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "တစ်/tn ကိုက်/v ကို/ppm ဝမ်/n ခုနှစ်ထောင်/tn ပါ/part ။/punc\n",
      "မနှစ်/n က/ppm သူ/n ကျွန်မ/pron ကို/ppm သင်/v ပေး/part တယ်/ppm ။/punc\n",
      "ကျွန်တော့်/pron ခုံ/n သွား/part ရှာ/v မလို့/part ။/punc\n",
      "အတန်း/n စ/v တာ/part ကြာ/v ပြီ/ppm လား/part ။/punc\n",
      "ဆေး/n နည်းနည်း/adj စား/v လိုက်/part ၊/punc သုံး/v လေး/part ရက်/n လောက်/part အနားယူ/v လိုက်/part ရင်/conj ပျောက်/v သွား/part မှာ/ppm ပါ/part ။/punc\n",
      "အေးချမ်း/v မှု/part နဲ့/ppm စည်းကမ်း/n ကို/ppm တည်မြဲ/v အောင်/conj ထိန်းသိမ်း/v သည်/ppm ။/punc\n",
      "ဇွန်း/n ကို/ppm လိုအပ်/v တယ်/ppm ။/punc\n",
      "ဘွဲ့/n ရ/v ရင်/part ဘာ/pron လုပ်/v မ/part လို့/part လဲ/part ။/punc\n",
      "ကျွန်တော်/pron ချောင်းဆိုး/v ခြင်း/part အတွက်/ppm တစ်/tn ခု/part ခု/part လို/v ချင်/part တယ်/ppm ။/punc\n",
      "အသီးအနှံ/n တို့/part မှ/ppm လွဲ/v လျှင်/conj လူ/n တို့/part ၏/ppm အဓိက/n အစားအစာ/n မှာ/ppm ငါး/n ဖြစ်/v သည်/ppm ။/punc\n"
     ]
    }
   ],
   "source": [
    "!head ../fst/otest_3gram.hyp.line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9977675-6f82-41ba-9eb6-a0c930e7787c",
   "metadata": {},
   "source": [
    "**Evaluation လုပ်မယ်။**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c5710a1f-4bde-419f-9633-293586655ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.00% (12660/13468)\n",
      "\n",
      "Most common mistakes:\n",
      "ရ/v --> ရ/part\t35\n",
      "ဒီ/pron --> ဒီ/adj\t23\n",
      "နဲ့/conj --> နဲ့/ppm\t17\n",
      "ပြီး/conj --> ပြီး/part\t16\n",
      "များ/adj --> များ/part\t15\n",
      "နှင့်/ppm --> နှင့်/conj\t14\n",
      "သွား/part --> သွား/v\t13\n",
      "ကောင်း/adj --> ကောင်း/v\t12\n",
      "ဘာ/adj --> ဘာ/pron\t12\n",
      "ပြီး/part --> ပြီး/conj\t12\n"
     ]
    }
   ],
   "source": [
    "!python ../script/pos_evaluation.py --ref ../data/otest.txt --hyp ../fst/otest_3gram.hyp.line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b8d8c-2064-454b-8b4f-cbad89413305",
   "metadata": {},
   "source": [
    "**ရလဒ်က တက်ပါတယ်။ ပထမ 2-gram LM နဲ့ run ထားတာကို Accuracy score ပြန်တွက်ကြည့်ရအောင်။**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "85696308-6cb0-4c02-9276-8a3f067f9c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.66% (12345/13468)\n",
      "\n",
      "Most common mistakes:\n",
      "ရ/part --> ရ/v\t91\n",
      "ပြီး/conj --> ပြီး/v\t73\n",
      "ပေး/part --> ပေး/v\t47\n",
      "သွား/part --> သွား/v\t36\n",
      "ဒီ/pron --> ဒီ/adj\t32\n",
      "နှင့်/ppm --> နှင့်/conj\t21\n",
      "နဲ့/conj --> နဲ့/ppm\t19\n",
      "ဘာ/pron --> ဘာ/adj\t18\n",
      "နှစ်/tn --> နှစ်/n\t18\n",
      "လာ/v --> လာ/part\t18\n"
     ]
    }
   ],
   "source": [
    "!python ../script/pos_evaluation.py --ref ../data/otest.txt --hyp ../fst/otest.hyp.line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a847bd3-64a2-417e-a980-e96fb97b41ed",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "WFST-based POS tagging ကို လက်တွေ့ လုပ်ပြခဲ့တယ်။  \n",
    "ဒေတာက myPOS (version 3.0) ကို သုံးခဲ့တယ်။  \n",
    "2-gram language model ကနေ 3-gram LM ကိုပြောင်းလိုက်တာနဲ့ POS tagging ရလဒ်က 91.66% ကနေ 94.00 ထိ တက်လာတာကို သက်သေပြခဲ့တယ်။  \n",
    "\n",
    "Weighted Finite State Transducers ရဲ့ ကောင်းတဲ့အချက်က text file အဖြစ် မော်ဒယ်ကို print ရိုက်ထုတ်လိုက်ပြီး အသေးစိတ် debug လုပ်လို့ ရတာကြောင့် transparent ဖြစ်တယ်။  \n",
    "အထူးသဖြင့် ဒေတာကပမာဏက နည်းရင် light-weight model တွေအနေနဲ့ဆောက်နိုင်တာမို့လို့ application အမျိုးမျိုးအတွက်လည်း အသုံးဝင်တယ်။\n",
    "တော်တော်များများ NLP task တွေအတွက် top result မဟုတ်ရင်တောင်မှ လွယ်လွယ်ကူကူနဲ့ Accuracy က 90% ဝန်းကျင် ရရှိနိုင်တယ်။  \n",
    "GPU မရှိလည်း အိုကေတယ်။  \n",
    "\n",
    "တခုရှိတာက WFST တွေက အခြေခံအားဖြင့်က supervised learning ပါ။ ဆိုလိုတာက tagged လုပ်ထားတဲ့ ဒေတာ၊ reference ဒေတာ ရှိမှ အိုကေတယ်။  \n",
    "တချို့ လက်တွေ့ အလုပ်တွေအတွက်က တခြား မော်ဒယ်တွေနဲ့ တွဲသုံးတာမျိုးလည်း လုပ်မှ ရလဒ်က ကောင်းတယ်။   \n",
    "\n",
    "POS tagging လုပ်တာ အစအဆုံးကို ဆရာက လုပ်ပြထားလို့ လွယ်သရောင်ရောင် ထင်ရပေမဲ့ ကိုယ်တိုင် NLP task အလုပ်အသစ် တမျိုးမျိုးကို WFST နဲ့ လုပ်ကြည့်ရင် ဘယ်လောက် ခက်ခဲတယ် ဆိုတာကို သိလာပါလိမ့်မယ်။ အလုပ်တခု အစအဆုံး ပြီးစီးဖို့အတွက်က coding တွေ အများကြီးလုပ်ရပါတယ်။ ပြီးတော့ OpenFST command တွေက error message မပေးပဲ ရပ်သွားတာမို့ debug လုပ်ရတာ ခက်ခဲတာတွေလည်းရှိပါတယ်။ အဲဒါကြောင့် နောက်ဆုံးအနေနဲ့ မှာချင်တာက တကယ်တမ်း WFST နဲ့အလုပ်လုပ်နိုင်ဖို့ ဆိုရင် မတူတဲ့ ဒေတာကို သုံးပြီး မတူတဲ့ NLP task တခုခုကို လုပ်ကြည့်ကြပါလို့ အကြံပေးချင်ပါတယ်။    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d385f944-cd25-4067-9af5-36fcaca85303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
